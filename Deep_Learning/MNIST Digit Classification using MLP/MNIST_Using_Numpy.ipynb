{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Importing libraries and Dataset initialization**"
      ],
      "metadata": {
        "id": "4bXa0ffSwCoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install np-utils\n",
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7o0GXU3z2Qlg",
        "outputId": "650e9192-645a-4cf3-b0b4-99c0a8a33029"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: np-utils in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.10/dist-packages (from np-utils) (1.26.4)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AY_hbEIDv5Es",
        "outputId": "6ea8c1aa-d016-4ee9-fc19-f522a7d0aabd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of training dataset size:  49  and testing dataset size:  49\n"
          ]
        }
      ],
      "source": [
        "import sklearn.datasets as dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "import keras.utils\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "data= dataset.load_iris()\n",
        "X= data.data\n",
        "Y= data.target\n",
        "Y=Y.reshape(150,1,1)\n",
        "X=X.reshape(150,1,4)\n",
        "X= X/np.linalg.norm(X)\n",
        "x_train,x_test,y_train,y_test=train_test_split(X,Y,train_size=0.33,random_state=42)\n",
        "y_train= to_categorical(y_train)\n",
        "y_test= to_categorical(y_test)\n",
        "print(\"Size of training dataset size: \", x_train.shape[0], \" and testing dataset size: \", y_train.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer:\n",
        "    def __init__(self,input_size,output_size):\n",
        "        self.input=None\n",
        "        self.output=None\n",
        "        self.weights= np.random.rand(input_size,output_size)-0.5\n",
        "        self.biases= np.random.rand(1,output_size)-0.5\n",
        "    def forward(self,input):\n",
        "        self.input=input\n",
        "        self.output= np.dot(self.input,self.weights)+self.biases\n",
        "        return self.output\n",
        "    def backward(self,o_error,alpha):\n",
        "        w_error= np.dot(self.input.T,o_error)\n",
        "        x_error= np.dot(o_error,self.weights.T)\n",
        "        self.weights=self.weights + w_error*alpha\n",
        "        self.biases=self.biases+alpha*o_error\n",
        "        return x_error"
      ],
      "metadata": {
        "id": "I1JoVs9J29cz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Activation_class:\n",
        "    def __init__(self,a_func,act_func_derivative):\n",
        "        self.activation= a_func\n",
        "        self.activation_derivative= act_func_derivative\n",
        "    def forward(self,input):\n",
        "        self.input= input\n",
        "        self.output= self.activation(self.input)\n",
        "        return self.output\n",
        "    def backward(self,y_error,alpha):\n",
        "        return self.activation_derivative(self.input)*y_error"
      ],
      "metadata": {
        "id": "DMq33fw_3CxK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NN:\n",
        "    def __init__(self):\n",
        "        self.layers=[]\n",
        "        self.error= lambda y_pred,y_true: np.mean(np.power(y_true-y_pred,2))\n",
        "        self.error_derivative= lambda y_true,y_output: 2*(y_true-y_output)/75\n",
        "    def adding_layer(self,layers):\n",
        "        self.layers.append(layers)\n",
        "    def fit_model(self,x,y,itera,alpha):\n",
        "        for i in range(itera):\n",
        "            p_e=[]\n",
        "            net_error=0\n",
        "            for j in range(49):\n",
        "                output=x[j]\n",
        "                for layers in self.layers:\n",
        "                    output= layers.forward(output)\n",
        "                error_occured= self.error(output,y[j])\n",
        "                net_error+=error_occured\n",
        "                error_derivative= self.error_derivative(y[j],output)\n",
        "                for layers in reversed(self.layers):\n",
        "                    error_derivative=layers.backward(error_derivative,alpha,)\n",
        "            net_error/=49\n",
        "            if(i%200==0):\n",
        "                print(\"iteration: \", i,\"error: \",net_error)\n",
        "        return net_error\n",
        "    def predict(self,input):\n",
        "        samples = len(input)\n",
        "        result =[]\n",
        "        for i in range(samples):\n",
        "            output = input[i]\n",
        "            for layers in self.layers:\n",
        "                output= layers.forward(output)\n",
        "            result.append(output)\n",
        "        return result\n",
        "    def accuracy(self,input):\n",
        "        ac = 0\n",
        "        samples = len(input)\n",
        "        for i in range(samples):\n",
        "            y_pred=self.predict(x_test[i])\n",
        "            y_pred= np.argmax(y_pred)\n",
        "            if(y_pred == np.argmax(y_test[i])):\n",
        "                ac+=1\n",
        "        acc = (ac/samples)*100\n",
        "        return acc"
      ],
      "metadata": {
        "id": "CDvE0uRv3GZU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Activation_Relu(x):\n",
        "    output = np.maximum(0, x)\n",
        "    return output\n",
        "def Activation_Relu_derivative(x):\n",
        "     return np.greater(x, 0.).astype(np.float64)\n",
        "\n",
        "def Activation_softmax_derivative(x):\n",
        "    return x*(1-x)\n",
        "def Activation_softmax(input):\n",
        "    exp_values = np.exp(input.astype(float))\n",
        "    prob= exp_values/np.sum(exp_values,keepdims=True)\n",
        "    return prob\n",
        "def sigmoid(input):\n",
        "    return 1/(1+(np.exp(-input)))\n",
        "def sigmoid_derivative(input):\n",
        "    return sigmoid(input)*(1 - sigmoid(input))"
      ],
      "metadata": {
        "id": "0uoDiNec3Q8i"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network= NN()\n",
        "network.adding_layer(Layer(4, 10))\n",
        "network.adding_layer(Activation_class(Activation_Relu,Activation_Relu_derivative))\n",
        "network.adding_layer(Layer(10, 8))\n",
        "network.adding_layer(Activation_class(Activation_Relu,Activation_Relu_derivative))\n",
        "network.adding_layer(Layer(8, 3))\n",
        "network.adding_layer(Activation_class(sigmoid,sigmoid_derivative))\n",
        "network.fit_model(x_train,y_train,30000,0.5)\n",
        "p=network.predict(x_test)\n",
        "q= network.accuracy(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQYtS9ep3WpW",
        "outputId": "3dd3952b-22f1-4027-f939-378580cbf92c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration:  0 error:  0.2760278832696755\n",
            "iteration:  200 error:  0.21835822233548077\n",
            "iteration:  400 error:  0.21830608776398153\n",
            "iteration:  600 error:  0.21822589536088086\n",
            "iteration:  800 error:  0.21808273162957734\n",
            "iteration:  1000 error:  0.21779320243690997\n",
            "iteration:  1200 error:  0.21710837796897653\n",
            "iteration:  1400 error:  0.215063567942995\n",
            "iteration:  1600 error:  0.2058763782971314\n",
            "iteration:  1800 error:  0.1581361924945213\n",
            "iteration:  2000 error:  0.12530317862371412\n",
            "iteration:  2200 error:  0.1149482879467615\n",
            "iteration:  2400 error:  0.10913043873146028\n",
            "iteration:  2600 error:  0.10528477870118665\n",
            "iteration:  2800 error:  0.10181242704266341\n",
            "iteration:  3000 error:  0.09809545363125921\n",
            "iteration:  3200 error:  0.09498323992658869\n",
            "iteration:  3400 error:  0.09087751987456395\n",
            "iteration:  3600 error:  0.08437515147965263\n",
            "iteration:  3800 error:  0.07341204371115737\n",
            "iteration:  4000 error:  0.059095852730848754\n",
            "iteration:  4200 error:  0.046624317865987565\n",
            "iteration:  4400 error:  0.0395039370162455\n",
            "iteration:  4600 error:  0.036408423712107216\n",
            "iteration:  4800 error:  0.033841260308884104\n",
            "iteration:  5000 error:  0.03239457421184074\n",
            "iteration:  5200 error:  0.030789936158330554\n",
            "iteration:  5400 error:  0.030005988017081396\n",
            "iteration:  5600 error:  0.029787313895965645\n",
            "iteration:  5800 error:  0.02910055507191542\n",
            "iteration:  6000 error:  0.02845799529958572\n",
            "iteration:  6200 error:  0.027769395129306453\n",
            "iteration:  6400 error:  0.02706391801863255\n",
            "iteration:  6600 error:  0.02637322926417472\n",
            "iteration:  6800 error:  0.025647716683746016\n",
            "iteration:  7000 error:  0.024858256647510908\n",
            "iteration:  7200 error:  0.0239219783089913\n",
            "iteration:  7400 error:  0.022868919914730338\n",
            "iteration:  7600 error:  0.02175170047868125\n",
            "iteration:  7800 error:  0.020596929502489765\n",
            "iteration:  8000 error:  0.019401342962571243\n",
            "iteration:  8200 error:  0.018136388464658343\n",
            "iteration:  8400 error:  0.01683810650160759\n",
            "iteration:  8600 error:  0.015248904796231656\n",
            "iteration:  8800 error:  0.013415347027648192\n",
            "iteration:  9000 error:  0.011710887340683731\n",
            "iteration:  9200 error:  0.01090301112440204\n",
            "iteration:  9400 error:  0.014506712770806372\n",
            "iteration:  9600 error:  0.013660483242806911\n",
            "iteration:  9800 error:  0.014002814778622447\n",
            "iteration:  10000 error:  0.014261841358507771\n",
            "iteration:  10200 error:  0.01432766381390091\n",
            "iteration:  10400 error:  0.01404218809730568\n",
            "iteration:  10600 error:  0.014306341209803815\n",
            "iteration:  10800 error:  0.014484260906942013\n",
            "iteration:  11000 error:  0.014582992129746966\n",
            "iteration:  11200 error:  0.014611672115511311\n",
            "iteration:  11400 error:  0.014609980419030626\n",
            "iteration:  11600 error:  0.014546755123962769\n",
            "iteration:  11800 error:  0.014439469507449385\n",
            "iteration:  12000 error:  0.014286738469658269\n",
            "iteration:  12200 error:  0.014116219510907042\n",
            "iteration:  12400 error:  0.013964509318845363\n",
            "iteration:  12600 error:  0.013830166298024641\n",
            "iteration:  12800 error:  0.013716852403148547\n",
            "iteration:  13000 error:  0.013616800960796782\n",
            "iteration:  13200 error:  0.013525788590503924\n",
            "iteration:  13400 error:  0.01344291641101555\n",
            "iteration:  13600 error:  0.013366592002376759\n",
            "iteration:  13800 error:  0.013296036132525368\n",
            "iteration:  14000 error:  0.013229604983701744\n",
            "iteration:  14200 error:  0.013166704621298278\n",
            "iteration:  14400 error:  0.013107757901522356\n",
            "iteration:  14600 error:  0.013046540992322312\n",
            "iteration:  14800 error:  0.01298522201741749\n",
            "iteration:  15000 error:  0.012921676580461137\n",
            "iteration:  15200 error:  0.012856578845731968\n",
            "iteration:  15400 error:  0.012789691047617511\n",
            "iteration:  15600 error:  0.012720472418903504\n",
            "iteration:  15800 error:  0.01264989644667342\n",
            "iteration:  16000 error:  0.012578754561475553\n",
            "iteration:  16200 error:  0.012507573202014188\n",
            "iteration:  16400 error:  0.012436678809401025\n",
            "iteration:  16600 error:  0.012367280356244266\n",
            "iteration:  16800 error:  0.012298633406039606\n",
            "iteration:  17000 error:  0.012231404777770042\n",
            "iteration:  17200 error:  0.012165705381384041\n",
            "iteration:  17400 error:  0.012101652378959233\n",
            "iteration:  17600 error:  0.012039242776728468\n",
            "iteration:  17800 error:  0.011978557563976772\n",
            "iteration:  18000 error:  0.011919515997274387\n",
            "iteration:  18200 error:  0.01186216350099499\n",
            "iteration:  18400 error:  0.011806466966197013\n",
            "iteration:  18600 error:  0.01175240838420568\n",
            "iteration:  18800 error:  0.011699989672843154\n",
            "iteration:  19000 error:  0.01164912996168074\n",
            "iteration:  19200 error:  0.011600055715568823\n",
            "iteration:  19400 error:  0.011552567484965321\n",
            "iteration:  19600 error:  0.011506717863788356\n",
            "iteration:  19800 error:  0.011462524753357623\n",
            "iteration:  20000 error:  0.01141993781644215\n",
            "iteration:  20200 error:  0.011379166181590577\n",
            "iteration:  20400 error:  0.011339918263775485\n",
            "iteration:  20600 error:  0.011302469492788526\n",
            "iteration:  20800 error:  0.011266517569051794\n",
            "iteration:  21000 error:  0.011232318291157953\n",
            "iteration:  21200 error:  0.011199627153067274\n",
            "iteration:  21400 error:  0.011168473818282173\n",
            "iteration:  21600 error:  0.011138809038946203\n",
            "iteration:  21800 error:  0.011086824256905378\n",
            "iteration:  22000 error:  0.011062418268173706\n",
            "iteration:  22200 error:  0.011039107538771811\n",
            "iteration:  22400 error:  0.011016854407437599\n",
            "iteration:  22600 error:  0.010995586162231522\n",
            "iteration:  22800 error:  0.01097524544653817\n",
            "iteration:  23000 error:  0.01095567927645723\n",
            "iteration:  23200 error:  0.010937048571828341\n",
            "iteration:  23400 error:  0.010920449320010394\n",
            "iteration:  23600 error:  0.01090311898082677\n",
            "iteration:  23800 error:  0.010886346017278354\n",
            "iteration:  24000 error:  0.010870504455428196\n",
            "iteration:  24200 error:  0.010855147284159681\n",
            "iteration:  24400 error:  0.010840028202598698\n",
            "iteration:  24600 error:  0.010825892239091355\n",
            "iteration:  24800 error:  0.01081183649814475\n",
            "iteration:  25000 error:  0.01079830036231144\n",
            "iteration:  25200 error:  0.01078488390627004\n",
            "iteration:  25400 error:  0.010772337413353442\n",
            "iteration:  25600 error:  0.01076606685708488\n",
            "iteration:  25800 error:  0.01075191733765247\n",
            "iteration:  26000 error:  0.010738662694729494\n",
            "iteration:  26200 error:  0.010725082357604063\n",
            "iteration:  26400 error:  0.010712442196811838\n",
            "iteration:  26600 error:  0.010700157802176967\n",
            "iteration:  26800 error:  0.010688338596402398\n",
            "iteration:  27000 error:  0.010676567434600505\n",
            "iteration:  27200 error:  0.010665415280562581\n",
            "iteration:  27400 error:  0.010653879126694377\n",
            "iteration:  27600 error:  0.010643213705443381\n",
            "iteration:  27800 error:  0.010632174490079221\n",
            "iteration:  28000 error:  0.010622100546180329\n",
            "iteration:  28200 error:  0.01061133901203132\n",
            "iteration:  28400 error:  0.010601211874628702\n",
            "iteration:  28600 error:  0.01059090654106678\n",
            "iteration:  28800 error:  0.010328521187472127\n",
            "iteration:  29000 error:  0.010251740146943049\n",
            "iteration:  29200 error:  0.010190330635237556\n",
            "iteration:  29400 error:  0.01013348402141705\n",
            "iteration:  29600 error:  0.010079368910616972\n",
            "iteration:  29800 error:  0.010027974522010983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5WHUkUm3gyT",
        "outputId": "0d0d1daa-a49f-4d32-a2da-24c7a69a0669"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97.02970297029702\n"
          ]
        }
      ]
    }
  ]
}