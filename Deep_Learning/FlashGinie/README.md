# ğŸ§ VoiceMoodMirror: Real-Time Voice Emotion Analyzer & Feedback

## ğŸ“Œ Project Overview

**VoiceMoodMirror** captures a user's speech (a few sentences), analyzes **prosodic features** like pitch, tempo, energy, and spectral characteristics to infer their current mood or emotional state, then provides **visual feedback** (e.g., color/animation dashboard) and/or **suggests or plays music** that matches or modulates that mood.

## ğŸ’¡ Use Cases

* Self-awareness / mood journaling tools
* Wellness apps (e.g., calming music when stressed)
* Interactive installations or smart mirrors
* Accessibility/emotion-aware assistants

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone <repository-url>
cd voicemoodmirror

# Install dependencies
pip install -r requirements.txt
```

### Running the Application

```bash
# Run the Streamlit dashboard
streamlit run ui/dashboard.py

# Or run the demo notebook
jupyter notebook examples/demo_notebook.ipynb
```

### Running Tests

```bash
# Run all tests
pytest

# Run tests with coverage
pytest --cov=.

# Run specific test file
pytest tests/test_audio_recorder.py
```

## ğŸ§  Core Components

### 1. Audio Capture & Feature Extraction
- **`audio/recorder.py`**: Microphone capture, buffering, preprocessing
- **`audio/feature_extractor.py`**: Extract pitch, tempo, energy, MFCCs, etc. (librosa)

### 2. Emotion Analysis
- **`emotion/prosody_classifier.py`**: Rule-based or ML model mapping prosodic features to mood
- **`emotion/mood_mapper.py`**: Maps inferred mood to visuals and music tags

### 3. Music Selection
- **`music/music_selector.py`**: Selects/queues music based on mood (local library or public API)
- **`music/playlist_builder.py`**: Builds adaptive playlists (e.g., calming if stressed)

### 4. User Interface
- **`ui/dashboard.py`**: Visual feedback (e.g., real-time mood meter, color gradients)

### 5. Utilities
- **`utils/smoothing.py`**: Temporal smoothing of noisy mood predictions

## ğŸ”§ Features

* ğŸ¤ Live or recorded voice input
* ğŸ“Š Real-time visualization of emotional state
* ğŸ¶ Adaptive music recommendation/player
* ğŸ” Temporal smoothing to avoid jittery mood flicker
* âš™ï¸ Configurable mood mappings (user can choose whether to reflect mood or counteract it)
* ğŸ§  Optional "mood history" log for self-reflection

## ğŸ§ª Possible Enhancements

* Add **speech-to-text** and combine **semantic sentiment** with prosody for richer inference
* Personalized calibration per user (baseline pitch/tempo)
* Support for multilingual voice input
* Mobile/web version using Web Audio API and TensorFlow.js
* Emotion change detection and notifications (e.g., "You seem more stressed than 10 minutes ago")
* Integrate with smart home to adjust lighting/music based on mood

## ğŸ“ Project Structure

```
voicemoodmirror/
â”‚
â”œâ”€â”€ audio/
â”‚   â”œâ”€â”€ recorder.py              # Microphone capture, buffering, preprocessing
â”‚   â””â”€â”€ feature_extractor.py     # Extract pitch, tempo, energy, MFCCs, etc. (librosa)
â”‚
â”œâ”€â”€ emotion/
â”‚   â”œâ”€â”€ prosody_classifier.py    # Rule-based or ML model mapping prosodic features to mood
â”‚   â”œâ”€â”€ model_training.py        # (Optional) Train a lightweight model on synthetic / annotated data
â”‚   â””â”€â”€ mood_mapper.py           # Maps inferred mood to visuals and music tags
â”‚
â”œâ”€â”€ music/
â”‚   â”œâ”€â”€ music_selector.py        # Selects/queues music based on mood (local library or public API)
â”‚   â””â”€â”€ playlist_builder.py      # Builds adaptive playlists (e.g., calming if stressed)
â”‚
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ dashboard.py             # Visual feedback (e.g., real-time mood meter, color gradients)
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ smoothing.py             # Temporal smoothing of noisy mood predictions
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_audio_recorder.py
â”‚   â”œâ”€â”€ test_feature_extractor.py
â”‚   â”œâ”€â”€ test_prosody_classifier.py
â”‚   â”œâ”€â”€ test_mood_mapper.py
â”‚   â”œâ”€â”€ test_music_selector.py
â”‚   â””â”€â”€ test_smoothing.py
â”‚
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ demo_notebook.ipynb      # Interactive demo with recorded audio samples
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.
