{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Species Segmentation with Cluster Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Iris flower dataset is one of the most popular ones for machine learning. You can read a lot about it online and have probably already heard of it: https://en.wikipedia.org/wiki/Iris_flower_data_set\n",
    "\n",
    "We didn't want to use it in the lectures, but believe that it would be very interesting for you to try it out (and maybe read about it on your own).\n",
    "\n",
    "There are 4 features: sepal length, sepal width, petal length, and petal width.\n",
    "\n",
    "Start by creating 2 clusters. Then standardize the data and try again. Does it make a difference?\n",
    "\n",
    "Use the Elbow rule to determine how many clusters are there.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from the csv file: <i> 'iris_dataset.csv'</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('iris_dataset.csv')\n",
    "# Check the data\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, try to cluster the iris flowers by the shape of their sepal. \n",
    "\n",
    "<i> Use the 'sepal_length' and 'sepal_width' variables.</i> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a scatter plot based on two corresponding features (sepal_length and sepal_width; OR petal_length and petal_width)\n",
    "plt.scatter(data['sepal_length'],data['sepal_width'])\n",
    "# name your axes\n",
    "plt.xlabel('Lenght of sepal')\n",
    "plt.ylabel('Width of sepal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering (unscaled data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a variable which will contain the data for the clustering\n",
    "x = data.copy()\n",
    "# create a k-means object with 2 clusters\n",
    "kmeans = KMeans(2)\n",
    "# fit the data\n",
    "kmeans.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of data, so we can see the clusters next to the original data\n",
    "clusters = data.copy()\n",
    "# predict the cluster for each observation\n",
    "clusters['cluster_pred']=kmeans.fit_predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a scatter plot based on two corresponding features (sepal_length and sepal_width; OR petal_length and petal_width)\n",
    "plt.scatter(clusters['sepal_length'], clusters['sepal_width'], c= clusters ['cluster_pred'], cmap = 'rainbow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and use the <i> scale </i> method from sklearn to standardize the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some preprocessing module\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# scale the data for better results\n",
    "x_scaled = preprocessing.scale(data)\n",
    "x_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering (scaled data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a k-means object with 2 clusters\n",
    "kmeans_scaled = KMeans(2)\n",
    "# fit the data\n",
    "kmeans_scaled.fit(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of data, so we can see the clusters next to the original data\n",
    "clusters_scaled = data.copy()\n",
    "# predict the cluster for each observation\n",
    "clusters_scaled['cluster_pred']=kmeans_scaled.fit_predict(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a scatter plot based on two corresponding features (sepal_length and sepal_width; OR petal_length and petal_width)\n",
    "plt.scatter(clusters_scaled['sepal_length'], clusters_scaled['sepal_width'], c= clusters_scaled ['cluster_pred'], cmap = 'rainbow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the two solutions are identical. That is because the original features have very similar scales to start with!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take Advantage of the Elbow Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WCSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss = []\n",
    "# 'cl_num' is a that keeps track the highest number of clusters we want to use the WCSS method for. \n",
    "# We have it set at 10 right now, but it is completely arbitrary.\n",
    "cl_num = 10\n",
    "for i in range (1,cl_num):\n",
    "    kmeans= KMeans(i)\n",
    "    kmeans.fit(x_scaled)\n",
    "    wcss_iter = kmeans.inertia_\n",
    "    wcss.append(wcss_iter)\n",
    "wcss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Elbow Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "number_clusters = range(1,cl_num)\n",
    "plt.plot(number_clusters, wcss)\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Within-cluster Sum of Squares')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like 2 or 3-cluster solutions are the best. \n",
    "\n",
    "To be continued... "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
