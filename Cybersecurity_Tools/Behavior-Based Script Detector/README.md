# ğŸ›¡ï¸ Behavior-Based Script Detector

A static analysis tool for Python scripts that detects potentially malicious or risky behavior by inspecting the code structure and patterns â€” without executing it.

## ğŸ“Œ Project Overview

Behavior-Based Script Detector is a Python-powered static code analyzer designed to evaluate .py scripts for suspicious or potentially harmful behavior. It uses Python's Abstract Syntax Tree (AST) to parse and analyze code structure, flagging risky operations like:

- Network activity (downloads, remote access)
- File system manipulation (deleting, modifying sensitive files)
- Process forking or shell execution
- Obfuscated or encoded code blocks

It assigns a behavioral risk score, highlights reasons for the score, and optionally suggests mitigation or safe alternatives.

## ğŸ” Key Features

### ğŸ§  Static AST-Based Analysis
- No execution required
- Safe for scanning unknown/untrusted scripts

### ğŸš© Detects Suspicious Patterns
- `os.system`, `subprocess`, `eval`, `exec`, `pickle`, etc.
- File writes to sensitive paths (`/etc`, `~/.ssh`)
- URL access / downloads
- Encoding/decoding functions (`base64`, `marshal`, etc.)

### ğŸ§¾ Risk Scoring System
- Each matched pattern contributes to an overall score
- Provides clear breakdown: which lines, which risks

### ğŸ“¦ Open-Source Vetting Mode
- Designed to vet unverified Python scripts and tools before use
- Can be integrated into CI/CD workflows or Git hooks

### ğŸ’¡ Explainable Output
- Easy-to-understand output with line numbers and reasons

## ğŸ› ï¸ Tech Stack

| Component | Library / Tool |
|-----------|----------------|
| AST Parsing | `ast`, `asttokens` |
| Risk Analysis | Custom ruleset |
| CLI Interface | `argparse`, `rich` |
| Optional TUI | `textual` |
| Report Export | `json`, `markdown`, `html` |

## ğŸ“‚ Project Structure

```
behavior_script_detector/
â”œâ”€â”€ analyzer/
â”‚   â”œâ”€â”€ pattern_rules.py
â”‚   â”œâ”€â”€ score_calculator.py
â”‚   â””â”€â”€ report_generator.py
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ test_malicious.py
â”œâ”€â”€ cli/
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ scan_results.json
â”‚   â””â”€â”€ flagged_code.md
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ file_loader.py
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_patterns.py
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

## ğŸ§ª Sample Usage

```bash
# Scan a script for suspicious behavior
python cli/main.py --file examples/test_malicious.py

# Output detailed report
python cli/main.py --file examples/test_malicious.py --report reports/

# Batch scan a directory of scripts
python cli/main.py --dir ./downloads/ --threshold 60
```

## ğŸ” Sample Output

```json
{
  "filename": "script.py",
  "risk_score": 78,
  "verdict": "High Risk",
  "suspicious_patterns": [
    {
      "line": 12,
      "pattern": "exec usage",
      "description": "Dynamic code execution using exec()"
    },
    {
      "line": 24,
      "pattern": "network download",
      "description": "Attempts to download files from remote URL"
    },
    {
      "line": 41,
      "pattern": "subprocess",
      "description": "Runs shell command using subprocess"
    }
  ]
}
```

## ğŸ“ˆ Use Cases

- âœ… Vetting untrusted or third-party Python scripts before execution
- ğŸ§ª Research and education on malware or obfuscation techniques
- ğŸ” Adding to security pipelines (e.g., GitHub Actions or pre-commit hooks)
- ğŸ§° Building a secure Python sandbox or malware analysis lab

## ğŸš€ Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd behavior-script-detector
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Run tests:
```bash
pytest tests/ -v
```

## ğŸ§ª Testing

Run the test suite:
```bash
pytest tests/ -v --cov=analyzer --cov=utils --cov=cli
```

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Run the test suite
6. Submit a pull request

## âš ï¸ Disclaimer

This tool is for educational and security research purposes. Always use responsibly and in accordance with applicable laws and regulations. 