Metadata-Version: 2.4
Name: lightflow
Version: 0.1.0
Summary: A lightweight parallel task pipeline framework
Author: Shivansh Katiyar
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: PyYAML>=6.0
Requires-Dist: click>=8.0.0
Requires-Dist: rich>=13.0.0
Requires-Dist: networkx>=3.0
Requires-Dist: graphviz>=0.20
Requires-Dist: pytest>=7.0.0
Requires-Dist: pytest-cov>=4.0.0
Dynamic: author
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# âš™ï¸ LightFlow: A Lightweight Parallel Task Pipeline Framework

> A minimal, Pythonic alternative to Airflow â€” run dependent tasks in parallel using threads or processes, from a simple YAML workflow file.

---

## ğŸ“Œ Project Overview

**LightFlow** is a lightweight, dependency-aware parallel task execution framework written in Python. It allows users to define workflows with steps and dependencies via a simple `YAML` or `JSON` file and executes them using multiprocessing or multithreading. It features real-time visualization of the **DAG (Directed Acyclic Graph)**, persistent checkpointing, failure logging, and retry logic.

Ideal for small-scale automation pipelines, CI tasks, ML model workflows, and more â€” without needing a full Apache Airflow setup.

---

## ğŸ¯ Key Features

- ğŸ§© **Workflow as Code**  
  Define tasks, dependencies, and execution strategies in a YAML or JSON file.

- ğŸš€ **Parallel Execution**  
  Run independent tasks concurrently using `concurrent.futures` or `multiprocessing`.

- ğŸ”— **DAG Visualization**  
  Generate and render task graphs using `graphviz` or `networkx`.

- ğŸ› ï¸ **Failure Recovery & Checkpointing**  
  Save progress, skip completed tasks, and retry failed ones on rerun.

- ğŸ“œ **Rich Logging**  
  Task stdout/stderr logs saved individually with timestamps.

- ğŸ“¦ **Plugin Architecture**  
  Easily define custom task types (e.g., shell commands, Python scripts, HTTP calls, etc.).

---

## ğŸ”§ Sample Workflow YAML

```yaml
workflow_name: daily_model_pipeline
tasks:
  fetch_data:
    run: python scripts/fetch.py
  preprocess:
    run: python scripts/clean.py
    depends_on: [fetch_data]
  train_model:
    run: python scripts/train.py
    depends_on: [preprocess]
  evaluate:
    run: python scripts/eval.py
    depends_on: [train_model]
  notify:
    run: curl -X POST https://webhook.site/send
    depends_on: [evaluate]
settings:
  max_parallel_tasks: 3
  retries: 2
  log_dir: logs/
```

---

## ğŸ§© Tech Stack

| Purpose | Library / Tool |
|---------|----------------|
| Task Execution | multiprocessing, threading, asyncio |
| DAG Parsing | networkx, pygraphviz |
| CLI Interface | click |
| Logging | logging, rich |
| YAML Support | PyYAML |
| Checkpointing | JSON snapshot |

---

## ğŸ“‚ Project Structure

```
lightflow/
â”œâ”€â”€ engine/
â”‚   â”œâ”€â”€ executor.py         # Thread/Process/Async manager
â”‚   â”œâ”€â”€ dag_builder.py      # Builds and validates DAG
â”‚   â”œâ”€â”€ checkpoint.py       # Saves and loads execution state
â”‚   â”œâ”€â”€ logger.py           # Rich logging interface
â”œâ”€â”€ parser/
â”‚   â””â”€â”€ workflow_loader.py  # Loads YAML/JSON workflow
â”œâ”€â”€ cli/
â”‚   â””â”€â”€ main.py             # Entry point for CLI
â”œâ”€â”€ plugins/
â”‚   â””â”€â”€ shell_task.py       # Executes shell tasks
â”‚   â””â”€â”€ python_task.py      # Executes Python functions
â”œâ”€â”€ visuals/
â”‚   â””â”€â”€ dag_viewer.py       # Generates DAG PNG/SVG
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ basic_workflow.yaml
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_*.py           # Unit tests
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ’» CLI Commands

```bash
# Run a workflow
lightflow run examples/basic_workflow.yaml

# Visualize DAG
lightflow dag --file examples/basic_workflow.yaml --output dag.svg

# Show task logs
lightflow logs --task train_model

# Resume failed workflow
lightflow resume examples/basic_workflow.yaml

# Validate workflow
lightflow validate examples/basic_workflow.yaml

# Create workflow template
lightflow template my_workflow

# List checkpoints
lightflow list-checkpoints workflow_name

# Clear checkpoints
lightflow clear workflow_name
```

---

## ğŸ” Checkpointing

- Each task's completion status is stored in a `.lightflow-checkpoint.json` file
- On rerun, completed tasks are skipped
- Failures are logged with exit codes and stack traces

---

## ğŸ“ˆ Future Enhancements

- [ ] Web dashboard for live task monitoring
- [ ] Cron-based scheduling
- [ ] Docker container support for task isolation
- [ ] GraphQL API to control tasks remotely
- [ ] Retry strategies per task (exponential backoff)

---

## ğŸ“œ License

MIT License â€” built for devs, data scientists, and tinkerers.

---

## ğŸ¤ Contributing

Open to PRs for:

- More task plugin types (e.g., SQL, HTTP, Lambda)
- DAG visual enhancements
- Async I/O support

---

## ğŸ”— Related Projects

- [Apache Airflow](https://airflow.apache.org/)
- [Luigi](https://github.com/spotify/luigi)
- [Prefect](https://www.prefect.io/)

---

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone <repository-url>
cd LightFlow

# Install dependencies
pip install -r requirements.txt

# Install in development mode
pip install -e .
```

### Basic Usage

1. **Create a workflow file** (`my_workflow.yaml`):
```yaml
workflow_name: my_first_workflow
tasks:
  hello:
    run: echo "Hello, LightFlow!"
    type: shell
    depends_on: []
  world:
    run: echo "World!"
    type: shell
    depends_on: [hello]
settings:
  max_parallel_tasks: 2
```

2. **Run the workflow**:
```bash
lightflow run my_workflow.yaml
```

3. **Visualize the DAG**:
```bash
lightflow dag --file my_workflow.yaml --output workflow.svg
```

### Examples

Check out the `examples/` directory for sample workflows:

- `basic_workflow.yaml` - Simple linear workflow
- `python_workflow.yaml` - Python-based data processing
- `parallel_workflow.yaml` - Parallel task execution

---

## ğŸ§ª Testing

Run the test suite:

```bash
# Install test dependencies
pip install pytest pytest-cov

# Run tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=lightflow --cov-report=html
```

---

## ğŸ“Š Performance

LightFlow is designed for small to medium-scale workflows:

- **Recommended**: Up to 50 tasks per workflow
- **Maximum**: 100+ tasks (with proper resource management)
- **Execution modes**: Thread, Process, Async
- **Parallelism**: Configurable worker pools

---

## ğŸ”§ Configuration

### Task Types

Currently supported task types:

- **shell**: Execute shell commands
- **python**: Execute Python code

### Settings

- `max_parallel_tasks`: Maximum concurrent tasks (default: 4)
- `retries`: Number of retry attempts (default: 0)
- `log_dir`: Directory for log files (default: "logs/")

---

## ğŸ› Troubleshooting

### Common Issues

1. **Graphviz not available**: Install with `pip install graphviz`
2. **Permission errors**: Ensure write permissions for log and checkpoint directories
3. **Task failures**: Check task output in log files

### Debug Mode

Enable debug logging:

```bash
lightflow run workflow.yaml --debug
```

---

## ğŸ“ Changelog

### v0.1.0
- Initial release
- Basic workflow execution
- YAML/JSON support
- DAG visualization
- Checkpointing system
- CLI interface

---

## ğŸ“ Support

- **Issues**: Create an issue on GitHub
- **Discussions**: Use GitHub Discussions
- **Documentation**: Check the examples and tests

---

## ğŸ™ Acknowledgments

- Inspired by Apache Airflow
- Built with Python's concurrent.futures
- Visualization powered by Graphviz
- Rich CLI experience with Click

---

Let me know if you'd like:
- A sample Python workflow to demo
- DAG SVG rendering with Graphviz
- Dockerized setup for easier use 
